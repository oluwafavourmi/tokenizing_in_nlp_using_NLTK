# tokenizing_in_nlp_using_NLTK

In the field of Natural Language Processing tokenization is an important concept
What is tokenization.

tokenization is the breaking down of a paragraph, Paragraphs can be broken to either sentences or words.
most of the times paragraphs are firstly broken down into sentences and further into words